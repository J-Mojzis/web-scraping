{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44db7694-299f-4710-8b21-c3d31f2706ed",
   "metadata": {},
   "source": [
    "## 1. Bibliotheken und Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28828a54-4172-49c2-91d1-0fd9be2ddcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4164e5dd-dff6-4f8c-8126-f0653f94a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome Options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})  # Disable images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcb283a-4923-47ac-b749-3ffd916af63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Chrome anti-bot measures\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b805783-005f-4248-992b-3a79ce3d1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver with Chrome options\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()), \n",
    "    options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2fbe79-36e6-4b32-ab0a-f5d928ae9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for cookies and initial URLs\n",
    "cookie_file_path = \"cookies.pkl\"\n",
    "base_url = \"https://finance.yahoo.com/\"\n",
    "sectors_url = \"https://finance.yahoo.com/sectors/basic-materials/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deda8325-8887-4b2b-ab55-cf6e4f49f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry function for operations\n",
    "def retry_operation(func, retries=3, delay=5, *args, **kwargs):\n",
    "    '''\n",
    "    Retries a function multiple times in case of failure, with a delay between attempts.\n",
    "    input:\n",
    "        - func: The function to be executed.\n",
    "        - retries: Number of retry attempts (default: 3).\n",
    "        - delay: Time (in seconds) between retry attempts (default: 5).\n",
    "        - *args, **kwargs: Arguments and keyword arguments for the function `func`.\n",
    "    output:\n",
    "        - Returns the output of the function `func` if successful, otherwise None after exhausting retries.\n",
    "    '''\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            time.sleep(delay)\n",
    "    print(\"Operation failed after retries.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025042a8-0a87-4b3e-b16a-e9974f6bbfd0",
   "metadata": {},
   "source": [
    "## 2. Cookie Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cc5208-744f-449d-adb8-2938fd349004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cookies function\n",
    "def save_cookies(driver, path):\n",
    "    '''\n",
    "    Save browser cookies to a file for session reuse.\n",
    "    input:\n",
    "        - driver: Selenium WebDriver instance.\n",
    "        - path: File path (string) to save the cookies (e.g., \"cookies.pkl\").\n",
    "    output:\n",
    "        - None. Saves cookies to the specified file.\n",
    "    '''\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(driver.get_cookies(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9ed2e6-2a5d-4713-98d2-27a8f9b076f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cookies function with domain check\n",
    "def load_cookies(driver, path):\n",
    "    '''\n",
    "    Load browser cookies from a file to restore a session.\n",
    "    input:\n",
    "        - driver: Selenium WebDriver instance.\n",
    "        - path: File path (string) from which cookies are loaded (e.g., \"cookies.pkl\").\n",
    "    output:\n",
    "        - Boolean: True if cookies are loaded successfully, False otherwise.\n",
    "    '''\n",
    "    try:\n",
    "        with open(path, \"rb\") as file:\n",
    "            cookies = pickle.load(file)\n",
    "            for cookie in cookies:\n",
    "                if \"domain\" in cookie and cookie[\"domain\"] in driver.current_url:\n",
    "                    driver.add_cookie(cookie)\n",
    "            return True\n",
    "    except FileNotFoundError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c406a-b1bb-44a0-a855-740462d6f4f6",
   "metadata": {},
   "source": [
    "## 3. Frontend: Industry and Quote Link Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ff5cc5-cdd2-49cd-a6f2-41c3ef0373e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold industry names\n",
    "industry_names = []\n",
    "\n",
    "def gather_industry_names(driver):\n",
    "    '''\n",
    "    Collects the names of industries listed on the Yahoo Finance sector page.\n",
    "    input:\n",
    "        - driver: Selenium WebDriver instance, already on the sector page.\n",
    "    output:\n",
    "        - None. Populates the global list `industry_names` with extracted industry names.\n",
    "    '''\n",
    "    global industry_names\n",
    "    # Reload sectors page if not on it\n",
    "    if driver.current_url != sectors_url:\n",
    "        print(\"Returning to sectors page...\")\n",
    "        driver.get(sectors_url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"tr.yf-k3njn8\"))\n",
    "        )\n",
    "        time.sleep(1)  # Short delay for additional page loading\n",
    "\n",
    "    # Select industry rows after page load\n",
    "    industry_rows = driver.find_elements(By.CSS_SELECTOR, \"tr.yf-k3njn8\")\n",
    "    print(f\"Found {len(industry_rows)} industries.\")\n",
    "\n",
    "    # Extract and clean names of the first 10 industries\n",
    "    industry_names = [\n",
    "        row.find_element(By.CSS_SELECTOR, \"td.name\").text for row in industry_rows[2:len(industry_rows)]#2:\n",
    "    ]\n",
    "    print(\"Collected industry names:\", industry_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16923010-55a1-48d9-8ea0-576c58cd50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls():\n",
    "    '''\n",
    "    Generates URLs for industries based on their names.\n",
    "    input:\n",
    "        - None. Uses the global list `industry_names` (populated by `gather_industry_names`).\n",
    "    output:\n",
    "        - List of URLs (strings) pointing to individual industry pages.\n",
    "    '''\n",
    "    # Generate URLs using industry names, replacing spaces with dashes and removing '&'\n",
    "    updated_urls = [\n",
    "        sectors_url + name.lower().replace('&', '').replace(' ', '-').replace('--', '-') + '/' \n",
    "        for name in industry_names\n",
    "    ]\n",
    "    return updated_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a58d82-0d7f-4ac4-b6c7-4b3b6c3622f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract \"/quote/.../\" hrefs from each URL in the list\n",
    "def extract_quote_links(driver, urls):\n",
    "    '''\n",
    "    Extracts valid stock quote links from Yahoo Finance industry pages.\n",
    "    input:\n",
    "        - driver: Selenium WebDriver instance.\n",
    "        - urls: List of industry page URLs (strings).\n",
    "    output:\n",
    "        - List of valid stock quote links (strings) filtered for uppercase tickers only.\n",
    "    '''\n",
    "    quote_links = []  # List to hold fully qualified extracted links\n",
    "\n",
    "    # Regular expression to validate tickers (uppercase letters only)\n",
    "    valid_ticker_pattern = re.compile(r\"/quote/([A-Z]+)(/|$)\")\n",
    "    \n",
    "    for index, url in enumerate(urls):\n",
    "        print(f\"Accessing URL {index + 1}/{len(urls)}: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Delay to allow page load; adjust as needed for speed optimization\n",
    "\n",
    "        # Parse the page source with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Find all hrefs that match \"/quote/.../\"\n",
    "        matched_links = []\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            if re.match(r\"^/quote/.+/$\", href):\n",
    "                full_url = urljoin(base_url, href)  # Prepend base URL\n",
    "\n",
    "                # Check if the link contains a valid ticker\n",
    "                if valid_ticker_pattern.search(full_url):\n",
    "                    matched_links.append(full_url)\n",
    "                    \n",
    "            # Stop after collecting the first 10 unique links\n",
    "            if len(matched_links) >= 10:\n",
    "                break\n",
    "\n",
    "        quote_links.extend(matched_links)\n",
    "\n",
    "        print(f\"Extracted {len(matched_links)} links from {url}\")\n",
    "\n",
    "    return quote_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784e030-e69e-41db-8b0b-9ee31c4f7d4c",
   "metadata": {},
   "source": [
    "## 4. Backend: Data Fetching and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "531e31e5-9687-4880-9a45-054a7763fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_tickers_data(links, cookies=None, headers=None):\n",
    "    '''\n",
    "    Fetches stock price data for multiple tickers and aligns it by timestamps.\n",
    "    input:\n",
    "        - links: List of stock quote links (strings).\n",
    "        - cookies: Dictionary of cookies for HTTP requests (default: None).\n",
    "        - headers: Dictionary of headers for HTTP requests (default: None).\n",
    "    output:\n",
    "        - pandas DataFrame: Contains timestamps as rows and stock tickers as columns, with their respective close prices.\n",
    "    '''\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # Calculate period1 (1 year ago) and period2 (current time)\n",
    "    period2 = int(datetime.now().timestamp())  # Current timestamp\n",
    "    period1 = int((datetime.now() - timedelta(days=365)).timestamp())  # 1 year ago\n",
    "    interval = \"1d\"  # Granularity: 1 day\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            # Extract the ticker symbol\n",
    "            ticker = link.split('/')[-2]\n",
    "            print(f\"Fetching data for {ticker}...\")\n",
    "\n",
    "            # Fetch data for the ticker\n",
    "            timestamps, close_prices = fetch_stock_data(\n",
    "                ticker, period1, period2, interval, cookies, headers\n",
    "            )\n",
    "            \n",
    "            if timestamps is not None and close_prices is not None:\n",
    "                print(f\"Fetched {len(close_prices)} daily close prices for {ticker}.\")\n",
    "                \n",
    "                # Create a DataFrame for this ticker\n",
    "                symbol_df = pd.DataFrame({\"timestamp\": timestamps[-100:], ticker: close_prices[-100:]})\n",
    "                all_data.append(symbol_df)\n",
    "            else:\n",
    "                print(f\"Warning: No data available for {ticker}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {link}: {e}\")\n",
    "\n",
    "    # Deduplicate tickers\n",
    "    unique_tickers = {df.columns[1]: df for df in all_data}\n",
    "    all_data = list(unique_tickers.values())\n",
    "\n",
    "    # Merge all data on \"timestamp\" using a full outer join\n",
    "    merged_data = pd.DataFrame()\n",
    "    for df in all_data:\n",
    "        if merged_data.empty:\n",
    "            merged_data = df\n",
    "        else:\n",
    "            merged_data = pd.merge(merged_data, df, on=\"timestamp\", how=\"outer\")\n",
    "\n",
    "    # Sort by timestamp\n",
    "    merged_data = merged_data.sort_values(by=\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8c635e1-838f-4db8-92ab-ad5cc324b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch stock data for a single ticker\n",
    "def fetch_stock_data(ticker, period1, period2, interval=\"1d\", cookies=None, headers=None):\n",
    "    '''\n",
    "    Fetches stock price data (timestamps and close prices) for a single ticker from Yahoo Finance.\n",
    "    input:\n",
    "        - ticker: Stock ticker symbol (string).\n",
    "        - period1: Start timestamp (int, in seconds since epoch).\n",
    "        - period2: End timestamp (int, in seconds since epoch).\n",
    "        - interval: Data granularity (string, e.g., \"1d\", \"1h\").\n",
    "        - cookies: Dictionary of cookies for the HTTP request (default: None).\n",
    "        - headers: Dictionary of headers for the HTTP request (default: None).\n",
    "    output:\n",
    "        - Tuple of two lists:\n",
    "            1. timestamps: List of datetime objects.\n",
    "            2. close_prices: List of float values representing close prices.\n",
    "        - Returns (None, None) if an error occurs.\n",
    "    '''\n",
    "    base_url = \"https://query1.finance.yahoo.com/v8/finance/chart/\"\n",
    "    query_url = (\n",
    "        f\"{base_url}{ticker}?period1={period1}&period2={period2}\"\n",
    "        f\"&interval={interval}&includePrePost=true&events=div%7Csplit%7Cearn&lang=en-US&region=US\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(query_url, cookies=cookies, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract timestamps and close prices\n",
    "        timestamps = data['chart']['result'][0]['timestamp']\n",
    "        close_prices = data['chart']['result'][0]['indicators']['quote'][0]['close']\n",
    "        \n",
    "        # Convert timestamps to datetime\n",
    "        timestamps = pd.to_datetime(timestamps, unit='s')\n",
    "\n",
    "        return timestamps, close_prices\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38a838b-e93c-41b7-a526-df025b536b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save extracted links to CSV, excluding links with invalid tickers\n",
    "def save_links_to_csv(links, filename=\"extracted_links.csv\"):\n",
    "    '''\n",
    "    Saves extracted stock quote links to a CSV file.\n",
    "    input:\n",
    "        - links: List of valid stock quote links (strings).\n",
    "        - filename: Output file path (string) for the CSV file (default: \"extracted_links.csv\").\n",
    "    output:\n",
    "        - None. Saves the links to the specified CSV file.\n",
    "    '''\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Link\"])  # Write header\n",
    "        for link in links:\n",
    "            writer.writerow([link])\n",
    "    \n",
    "    print(f\"Filtered links saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74adc635-89d5-4ba9-a6a9-c6f95758cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aggregated data to CSV\n",
    "def save_data_to_csv(data, filename=\"stock_data.csv\"):\n",
    "    '''\n",
    "    Saves a pandas DataFrame containing stock data to a CSV file.\n",
    "    input:\n",
    "        - data: pandas DataFrame with stock data.\n",
    "        - filename: Output file path (string) for the CSV file (default: \"stock_data.csv\").\n",
    "    output:\n",
    "        - None. Saves the DataFrame to the specified file.\n",
    "    '''\n",
    "    data.to_csv(filename, index=False)\n",
    "    print(f\"Stock data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89af9e-5ba9-4780-a5e2-ca9a37cfa52f",
   "metadata": {},
   "source": [
    "## 5. Main Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93e90a6e-c735-4154-95fd-24ddeba7da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to handle navigation\n",
    "def main():\n",
    "    '''\n",
    "    Main workflow that orchestrates web scraping, data extraction, and saving.\n",
    "    input:\n",
    "        - None.\n",
    "    output:\n",
    "        - None. Executes the end-to-end process of scraping, extracting, and saving stock data.\n",
    "    '''\n",
    "    print(\"Navigating to Yahoo Finance homepage...\")\n",
    "    driver.get(base_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Handle cookies if they exist\n",
    "    if load_cookies(driver, cookie_file_path):\n",
    "        print(\"Cookies loaded successfully.\")\n",
    "        driver.refresh()\n",
    "    else:\n",
    "        print(\"No cookies found. Accepting cookies manually.\")\n",
    "        try:\n",
    "            accept_button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept all')]\"))\n",
    "            )\n",
    "            accept_button.click()\n",
    "            time.sleep(2)\n",
    "            save_cookies(driver, cookie_file_path)\n",
    "            print(\"Cookies accepted and saved.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error handling cookies:\", e)\n",
    "    \n",
    "    # Navigate to Basic Materials sector\n",
    "    print(\"Navigating to Basic Materials sector...\")\n",
    "    driver.get(sectors_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Navigate to each industry and collect company links\n",
    "    #navigate_to_industry()\n",
    "    gather_industry_names(driver)\n",
    "    updated_urls = generate_urls()\n",
    "\n",
    "    print(\"List of updated URLs for the first 10 industries:\")\n",
    "    for url in updated_urls:\n",
    "        print(url)\n",
    "\n",
    "    # Extract quote links from each updated URL\n",
    "    print(\"Extracting /quote/.../ links from each industry page...\")\n",
    "    extracted_links = retry_operation(extract_quote_links, retries=3, driver=driver, urls=updated_urls)\n",
    "    if not extracted_links:\n",
    "        print(\"Failed to extract links. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    print(\"Collected full quote links:\") if extracted_links else print(\"Links could not be collected\")\n",
    "\n",
    "    # Save the extracted links\n",
    "    save_links_to_csv(extracted_links)\n",
    "    print(\"Extraction and saving complete.\")\n",
    "    \n",
    "    for link in extracted_links:\n",
    "        print(link)\n",
    "\n",
    "    # Fetch stock data using Yahoo AJAX endpoint\n",
    "    print(\"Fetching stock data for all links...\")\n",
    "    \n",
    "    # Define a fixed timestamp range\n",
    "    # Define the time range (6th November 2024 to 15th November 2024)\n",
    "    period1 = int(datetime(2024, 11, 6).timestamp())  # Start timestamp\n",
    "    period2 = int(datetime(2024, 11, 15).timestamp())  # End timestamp\n",
    "\n",
    "    # Define headers and cookies\n",
    "    cookies = {\n",
    "        \"GUC\": \"AQABCAFnJy1nV0IgvASK&s=AQAAAJB-qKHi&g=ZyXotw\",\n",
    "        \"A1\": \"d=AQABBK3oJWcCEL768yJfkpdKJoPN52K9l3QFEgABCAEtJ2dXZ7u9b2UBAiAAAAcIpuglZ8iQvhs&S=AQAAAq11kqwbV-Cl4YdEYNtEpg8\",\n",
    "        \"A3\": \"d=AQABBK3oJWcCEL768yJfkpdKJoPN52K9l3QFEgABCAEtJ2dXZ7u9b2UBAiAAAAcIpuglZ8iQvhs&S=AQAAAq11kqwbV-Cl4YdEYNtEpg8\",\n",
    "        \"A1S\": \"d=AQABBK3oJWcCEL768yJfkpdKJoPN52K9l3QFEgABCAEtJ2dXZ7u9b2UBAiAAAAcIpuglZ8iQvhs&S=AQAAAq11kqwbV-Cl4YdEYNtEpg8\",\n",
    "        \"cmp\": \"t=1733097066&j=1&u=1---&v=54\",\n",
    "        \"EuConsent\": \"CQHdjMAQHdjMAAOACKENBRFgAAAAAAAAACiQAAAAAAAA\",\n",
    "        \"PRF\": \"t=LIN%252BGC%253DF\",\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"accept\": \"*/*\",\n",
    "        \"accept-encoding\": \"gzip, deflate, br, zstd\",\n",
    "        \"accept-language\": \"de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n",
    "    }\n",
    "\n",
    "    # Fetch and save stock data\n",
    "    stock_data = fetch_all_tickers_data(extracted_links, cookies=cookies, headers=headers)\n",
    "    save_data_to_csv(stock_data)\n",
    "    print(\"Data fetching and saving complete.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "976582b1-9554-40bb-a2fc-fbd8ad44d8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to Yahoo Finance homepage...\n",
      "Cookies loaded successfully.\n",
      "Navigating to Basic Materials sector...\n",
      "Found 16 industries.\n",
      "Collected industry names: ['Specialty Chemicals', 'Gold', 'Building Materials', 'Copper', 'Steel', 'Agricultural Inputs', 'Chemicals', 'Other Industrial Metals & Mining', 'Lumber & Wood Production', 'Aluminum', 'Other Precious Metals & Mining', 'Coking Coal', 'Paper & Paper Products', 'Silver']\n",
      "List of updated URLs for the first 10 industries:\n",
      "https://finance.yahoo.com/sectors/basic-materials/specialty-chemicals/\n",
      "https://finance.yahoo.com/sectors/basic-materials/gold/\n",
      "https://finance.yahoo.com/sectors/basic-materials/building-materials/\n",
      "https://finance.yahoo.com/sectors/basic-materials/copper/\n",
      "https://finance.yahoo.com/sectors/basic-materials/steel/\n",
      "https://finance.yahoo.com/sectors/basic-materials/agricultural-inputs/\n",
      "https://finance.yahoo.com/sectors/basic-materials/chemicals/\n",
      "https://finance.yahoo.com/sectors/basic-materials/other-industrial-metals-mining/\n",
      "https://finance.yahoo.com/sectors/basic-materials/lumber-wood-production/\n",
      "https://finance.yahoo.com/sectors/basic-materials/aluminum/\n",
      "https://finance.yahoo.com/sectors/basic-materials/other-precious-metals-mining/\n",
      "https://finance.yahoo.com/sectors/basic-materials/coking-coal/\n",
      "https://finance.yahoo.com/sectors/basic-materials/paper-paper-products/\n",
      "https://finance.yahoo.com/sectors/basic-materials/silver/\n",
      "Extracting /quote/.../ links from each industry page...\n",
      "Accessing URL 1/14: https://finance.yahoo.com/sectors/basic-materials/specialty-chemicals/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/specialty-chemicals/\n",
      "Accessing URL 2/14: https://finance.yahoo.com/sectors/basic-materials/gold/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/gold/\n",
      "Accessing URL 3/14: https://finance.yahoo.com/sectors/basic-materials/building-materials/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/building-materials/\n",
      "Accessing URL 4/14: https://finance.yahoo.com/sectors/basic-materials/copper/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/copper/\n",
      "Accessing URL 5/14: https://finance.yahoo.com/sectors/basic-materials/steel/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/steel/\n",
      "Accessing URL 6/14: https://finance.yahoo.com/sectors/basic-materials/agricultural-inputs/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/agricultural-inputs/\n",
      "Accessing URL 7/14: https://finance.yahoo.com/sectors/basic-materials/chemicals/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/chemicals/\n",
      "Accessing URL 8/14: https://finance.yahoo.com/sectors/basic-materials/other-industrial-metals-mining/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/other-industrial-metals-mining/\n",
      "Accessing URL 9/14: https://finance.yahoo.com/sectors/basic-materials/lumber-wood-production/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/lumber-wood-production/\n",
      "Accessing URL 10/14: https://finance.yahoo.com/sectors/basic-materials/aluminum/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/aluminum/\n",
      "Accessing URL 11/14: https://finance.yahoo.com/sectors/basic-materials/other-precious-metals-mining/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/other-precious-metals-mining/\n",
      "Accessing URL 12/14: https://finance.yahoo.com/sectors/basic-materials/coking-coal/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/coking-coal/\n",
      "Accessing URL 13/14: https://finance.yahoo.com/sectors/basic-materials/paper-paper-products/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/paper-paper-products/\n",
      "Accessing URL 14/14: https://finance.yahoo.com/sectors/basic-materials/silver/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/silver/\n",
      "Collected full quote links:\n",
      "Filtered links saved to extracted_links.csv\n",
      "Extraction and saving complete.\n",
      "https://finance.yahoo.com/quote/LIN/\n",
      "https://finance.yahoo.com/quote/SHW/\n",
      "https://finance.yahoo.com/quote/APD/\n",
      "https://finance.yahoo.com/quote/ECL/\n",
      "https://finance.yahoo.com/quote/DD/\n",
      "https://finance.yahoo.com/quote/PPG/\n",
      "https://finance.yahoo.com/quote/LYB/\n",
      "https://finance.yahoo.com/quote/IFF/\n",
      "https://finance.yahoo.com/quote/RPM/\n",
      "https://finance.yahoo.com/quote/WLK/\n",
      "https://finance.yahoo.com/quote/NEM/\n",
      "https://finance.yahoo.com/quote/AU/\n",
      "https://finance.yahoo.com/quote/RGLD/\n",
      "https://finance.yahoo.com/quote/CDE/\n",
      "https://finance.yahoo.com/quote/SA/\n",
      "https://finance.yahoo.com/quote/CMCL/\n",
      "https://finance.yahoo.com/quote/CTGO/\n",
      "https://finance.yahoo.com/quote/IDR/\n",
      "https://finance.yahoo.com/quote/FTCO/\n",
      "https://finance.yahoo.com/quote/USAU/\n",
      "https://finance.yahoo.com/quote/CRH/\n",
      "https://finance.yahoo.com/quote/VMC/\n",
      "https://finance.yahoo.com/quote/MLM/\n",
      "https://finance.yahoo.com/quote/EXP/\n",
      "https://finance.yahoo.com/quote/SUM/\n",
      "https://finance.yahoo.com/quote/KNF/\n",
      "https://finance.yahoo.com/quote/BCC/\n",
      "https://finance.yahoo.com/quote/USLM/\n",
      "https://finance.yahoo.com/quote/TGLS/\n",
      "https://finance.yahoo.com/quote/SMID/\n",
      "https://finance.yahoo.com/quote/SCCO/\n",
      "https://finance.yahoo.com/quote/FCX/\n",
      "https://finance.yahoo.com/quote/IE/\n",
      "https://finance.yahoo.com/quote/MTAL/\n",
      "https://finance.yahoo.com/quote/SCCO/\n",
      "https://finance.yahoo.com/quote/MTAL/\n",
      "https://finance.yahoo.com/quote/FCX/\n",
      "https://finance.yahoo.com/quote/IE/\n",
      "https://finance.yahoo.com/quote/SCCO/\n",
      "https://finance.yahoo.com/quote/FCX/\n",
      "https://finance.yahoo.com/quote/NUE/\n",
      "https://finance.yahoo.com/quote/STLD/\n",
      "https://finance.yahoo.com/quote/RS/\n",
      "https://finance.yahoo.com/quote/X/\n",
      "https://finance.yahoo.com/quote/CMC/\n",
      "https://finance.yahoo.com/quote/CLF/\n",
      "https://finance.yahoo.com/quote/WS/\n",
      "https://finance.yahoo.com/quote/MTUS/\n",
      "https://finance.yahoo.com/quote/RDUS/\n",
      "https://finance.yahoo.com/quote/ZEUS/\n",
      "https://finance.yahoo.com/quote/CTVA/\n",
      "https://finance.yahoo.com/quote/CF/\n",
      "https://finance.yahoo.com/quote/MOS/\n",
      "https://finance.yahoo.com/quote/FMC/\n",
      "https://finance.yahoo.com/quote/SMG/\n",
      "https://finance.yahoo.com/quote/UAN/\n",
      "https://finance.yahoo.com/quote/LVRO/\n",
      "https://finance.yahoo.com/quote/BIOX/\n",
      "https://finance.yahoo.com/quote/IPI/\n",
      "https://finance.yahoo.com/quote/AVD/\n",
      "https://finance.yahoo.com/quote/DOW/\n",
      "https://finance.yahoo.com/quote/CE/\n",
      "https://finance.yahoo.com/quote/OLN/\n",
      "https://finance.yahoo.com/quote/HUN/\n",
      "https://finance.yahoo.com/quote/TROX/\n",
      "https://finance.yahoo.com/quote/ASIX/\n",
      "https://finance.yahoo.com/quote/WLKP/\n",
      "https://finance.yahoo.com/quote/VHI/\n",
      "https://finance.yahoo.com/quote/REX/\n",
      "https://finance.yahoo.com/quote/GPRE/\n",
      "https://finance.yahoo.com/quote/MP/\n",
      "https://finance.yahoo.com/quote/MTRN/\n",
      "https://finance.yahoo.com/quote/NEXA/\n",
      "https://finance.yahoo.com/quote/CMP/\n",
      "https://finance.yahoo.com/quote/CRML/\n",
      "https://finance.yahoo.com/quote/LZM/\n",
      "https://finance.yahoo.com/quote/GRO/\n",
      "https://finance.yahoo.com/quote/PLL/\n",
      "https://finance.yahoo.com/quote/USGO/\n",
      "https://finance.yahoo.com/quote/ATLX/\n",
      "https://finance.yahoo.com/quote/UFPI/\n",
      "https://finance.yahoo.com/quote/SSD/\n",
      "https://finance.yahoo.com/quote/UFPI/\n",
      "https://finance.yahoo.com/quote/SSD/\n",
      "https://finance.yahoo.com/quote/SSD/\n",
      "https://finance.yahoo.com/quote/UFPI/\n",
      "https://finance.yahoo.com/quote/NVCR/\n",
      "https://finance.yahoo.com/quote/SMCI/\n",
      "https://finance.yahoo.com/quote/PTCT/\n",
      "https://finance.yahoo.com/quote/NBIS/\n",
      "https://finance.yahoo.com/quote/AA/\n",
      "https://finance.yahoo.com/quote/CENX/\n",
      "https://finance.yahoo.com/quote/CSTM/\n",
      "https://finance.yahoo.com/quote/KALU/\n",
      "https://finance.yahoo.com/quote/CENX/\n",
      "https://finance.yahoo.com/quote/AA/\n",
      "https://finance.yahoo.com/quote/KALU/\n",
      "https://finance.yahoo.com/quote/CSTM/\n",
      "https://finance.yahoo.com/quote/CENX/\n",
      "https://finance.yahoo.com/quote/KALU/\n",
      "https://finance.yahoo.com/quote/HL/\n",
      "https://finance.yahoo.com/quote/GATO/\n",
      "https://finance.yahoo.com/quote/MUX/\n",
      "https://finance.yahoo.com/quote/ACRG/\n",
      "https://finance.yahoo.com/quote/GATO/\n",
      "https://finance.yahoo.com/quote/MUX/\n",
      "https://finance.yahoo.com/quote/HL/\n",
      "https://finance.yahoo.com/quote/ACRG/\n",
      "https://finance.yahoo.com/quote/GATO/\n",
      "https://finance.yahoo.com/quote/MUX/\n",
      "https://finance.yahoo.com/quote/HCC/\n",
      "https://finance.yahoo.com/quote/AMR/\n",
      "https://finance.yahoo.com/quote/ARCH/\n",
      "https://finance.yahoo.com/quote/SXC/\n",
      "https://finance.yahoo.com/quote/METC/\n",
      "https://finance.yahoo.com/quote/SXC/\n",
      "https://finance.yahoo.com/quote/HCC/\n",
      "https://finance.yahoo.com/quote/ARCH/\n",
      "https://finance.yahoo.com/quote/AMR/\n",
      "https://finance.yahoo.com/quote/METC/\n",
      "https://finance.yahoo.com/quote/SLVM/\n",
      "https://finance.yahoo.com/quote/MAGN/\n",
      "https://finance.yahoo.com/quote/CLW/\n",
      "https://finance.yahoo.com/quote/MERC/\n",
      "https://finance.yahoo.com/quote/GLT/\n",
      "https://finance.yahoo.com/quote/SLVM/\n",
      "https://finance.yahoo.com/quote/GLT/\n",
      "https://finance.yahoo.com/quote/MAGN/\n",
      "https://finance.yahoo.com/quote/CLW/\n",
      "https://finance.yahoo.com/quote/MERC/\n",
      "https://finance.yahoo.com/quote/RSMXF/\n",
      "https://finance.yahoo.com/quote/AYASF/\n",
      "https://finance.yahoo.com/quote/SVRSF/\n",
      "https://finance.yahoo.com/quote/APGOF/\n",
      "https://finance.yahoo.com/quote/KOOYF/\n",
      "https://finance.yahoo.com/quote/GSVRF/\n",
      "https://finance.yahoo.com/quote/SLVRF/\n",
      "https://finance.yahoo.com/quote/RKHNF/\n",
      "https://finance.yahoo.com/quote/WEDXF/\n",
      "https://finance.yahoo.com/quote/SVM/\n",
      "Fetching stock data for all links...\n",
      "Fetching data for LIN...\n",
      "Fetched 251 daily close prices for LIN.\n",
      "Fetching data for SHW...\n",
      "Fetched 251 daily close prices for SHW.\n",
      "Fetching data for APD...\n",
      "Fetched 251 daily close prices for APD.\n",
      "Fetching data for ECL...\n",
      "Fetched 251 daily close prices for ECL.\n",
      "Fetching data for DD...\n",
      "Fetched 251 daily close prices for DD.\n",
      "Fetching data for PPG...\n",
      "Fetched 251 daily close prices for PPG.\n",
      "Fetching data for LYB...\n",
      "Fetched 251 daily close prices for LYB.\n",
      "Fetching data for IFF...\n",
      "Fetched 251 daily close prices for IFF.\n",
      "Fetching data for RPM...\n",
      "Fetched 251 daily close prices for RPM.\n",
      "Fetching data for WLK...\n",
      "Fetched 251 daily close prices for WLK.\n",
      "Fetching data for NEM...\n",
      "Fetched 251 daily close prices for NEM.\n",
      "Fetching data for AU...\n",
      "Fetched 251 daily close prices for AU.\n",
      "Fetching data for RGLD...\n",
      "Fetched 251 daily close prices for RGLD.\n",
      "Fetching data for CDE...\n",
      "Fetched 251 daily close prices for CDE.\n",
      "Fetching data for SA...\n",
      "Fetched 251 daily close prices for SA.\n",
      "Fetching data for CMCL...\n",
      "Fetched 251 daily close prices for CMCL.\n",
      "Fetching data for CTGO...\n",
      "Fetched 251 daily close prices for CTGO.\n",
      "Fetching data for IDR...\n",
      "Fetched 251 daily close prices for IDR.\n",
      "Fetching data for FTCO...\n",
      "Fetched 251 daily close prices for FTCO.\n",
      "Fetching data for USAU...\n",
      "Fetched 251 daily close prices for USAU.\n",
      "Fetching data for CRH...\n",
      "Fetched 251 daily close prices for CRH.\n",
      "Fetching data for VMC...\n",
      "Fetched 251 daily close prices for VMC.\n",
      "Fetching data for MLM...\n",
      "Fetched 251 daily close prices for MLM.\n",
      "Fetching data for EXP...\n",
      "Fetched 251 daily close prices for EXP.\n",
      "Fetching data for SUM...\n",
      "Fetched 251 daily close prices for SUM.\n",
      "Fetching data for KNF...\n",
      "Fetched 251 daily close prices for KNF.\n",
      "Fetching data for BCC...\n",
      "Fetched 251 daily close prices for BCC.\n",
      "Fetching data for USLM...\n",
      "Fetched 251 daily close prices for USLM.\n",
      "Fetching data for TGLS...\n",
      "Fetched 251 daily close prices for TGLS.\n",
      "Fetching data for SMID...\n",
      "Fetched 251 daily close prices for SMID.\n",
      "Fetching data for SCCO...\n",
      "Fetched 251 daily close prices for SCCO.\n",
      "Fetching data for FCX...\n",
      "Fetched 251 daily close prices for FCX.\n",
      "Fetching data for IE...\n",
      "Fetched 251 daily close prices for IE.\n",
      "Fetching data for MTAL...\n",
      "Fetched 251 daily close prices for MTAL.\n",
      "Fetching data for SCCO...\n",
      "Fetched 251 daily close prices for SCCO.\n",
      "Fetching data for MTAL...\n",
      "Fetched 251 daily close prices for MTAL.\n",
      "Fetching data for FCX...\n",
      "Fetched 251 daily close prices for FCX.\n",
      "Fetching data for IE...\n",
      "Fetched 251 daily close prices for IE.\n",
      "Fetching data for SCCO...\n",
      "Fetched 251 daily close prices for SCCO.\n",
      "Fetching data for FCX...\n",
      "Fetched 251 daily close prices for FCX.\n",
      "Fetching data for NUE...\n",
      "Fetched 251 daily close prices for NUE.\n",
      "Fetching data for STLD...\n",
      "Fetched 251 daily close prices for STLD.\n",
      "Fetching data for RS...\n",
      "Fetched 251 daily close prices for RS.\n",
      "Fetching data for X...\n",
      "Fetched 251 daily close prices for X.\n",
      "Fetching data for CMC...\n",
      "Fetched 251 daily close prices for CMC.\n",
      "Fetching data for CLF...\n",
      "Fetched 251 daily close prices for CLF.\n",
      "Fetching data for WS...\n",
      "Fetched 251 daily close prices for WS.\n",
      "Fetching data for MTUS...\n",
      "Fetched 251 daily close prices for MTUS.\n",
      "Fetching data for RDUS...\n",
      "Fetched 251 daily close prices for RDUS.\n",
      "Fetching data for ZEUS...\n",
      "Fetched 251 daily close prices for ZEUS.\n",
      "Fetching data for CTVA...\n",
      "Fetched 251 daily close prices for CTVA.\n",
      "Fetching data for CF...\n",
      "Fetched 251 daily close prices for CF.\n",
      "Fetching data for MOS...\n",
      "Fetched 251 daily close prices for MOS.\n",
      "Fetching data for FMC...\n",
      "Fetched 251 daily close prices for FMC.\n",
      "Fetching data for SMG...\n",
      "Fetched 251 daily close prices for SMG.\n",
      "Fetching data for UAN...\n",
      "Fetched 251 daily close prices for UAN.\n",
      "Fetching data for LVRO...\n",
      "Fetched 251 daily close prices for LVRO.\n",
      "Fetching data for BIOX...\n",
      "Fetched 251 daily close prices for BIOX.\n",
      "Fetching data for IPI...\n",
      "Fetched 251 daily close prices for IPI.\n",
      "Fetching data for AVD...\n",
      "Fetched 251 daily close prices for AVD.\n",
      "Fetching data for DOW...\n",
      "Fetched 251 daily close prices for DOW.\n",
      "Fetching data for CE...\n",
      "Fetched 251 daily close prices for CE.\n",
      "Fetching data for OLN...\n",
      "Fetched 251 daily close prices for OLN.\n",
      "Fetching data for HUN...\n",
      "Fetched 251 daily close prices for HUN.\n",
      "Fetching data for TROX...\n",
      "Fetched 251 daily close prices for TROX.\n",
      "Fetching data for ASIX...\n",
      "Fetched 251 daily close prices for ASIX.\n",
      "Fetching data for WLKP...\n",
      "Fetched 251 daily close prices for WLKP.\n",
      "Fetching data for VHI...\n",
      "Fetched 251 daily close prices for VHI.\n",
      "Fetching data for REX...\n",
      "Fetched 251 daily close prices for REX.\n",
      "Fetching data for GPRE...\n",
      "Fetched 251 daily close prices for GPRE.\n",
      "Fetching data for MP...\n",
      "Fetched 251 daily close prices for MP.\n",
      "Fetching data for MTRN...\n",
      "Fetched 251 daily close prices for MTRN.\n",
      "Fetching data for NEXA...\n",
      "Fetched 251 daily close prices for NEXA.\n",
      "Fetching data for CMP...\n",
      "Fetched 251 daily close prices for CMP.\n",
      "Fetching data for CRML...\n",
      "Fetched 251 daily close prices for CRML.\n",
      "Fetching data for LZM...\n",
      "Fetched 251 daily close prices for LZM.\n",
      "Fetching data for GRO...\n",
      "Fetched 3 daily close prices for GRO.\n",
      "Fetching data for PLL...\n",
      "Fetched 251 daily close prices for PLL.\n",
      "Fetching data for USGO...\n",
      "Fetched 251 daily close prices for USGO.\n",
      "Fetching data for ATLX...\n",
      "Fetched 251 daily close prices for ATLX.\n",
      "Fetching data for UFPI...\n",
      "Fetched 251 daily close prices for UFPI.\n",
      "Fetching data for SSD...\n",
      "Fetched 251 daily close prices for SSD.\n",
      "Fetching data for UFPI...\n",
      "Fetched 251 daily close prices for UFPI.\n",
      "Fetching data for SSD...\n",
      "Fetched 251 daily close prices for SSD.\n",
      "Fetching data for SSD...\n",
      "Fetched 251 daily close prices for SSD.\n",
      "Fetching data for UFPI...\n",
      "Fetched 251 daily close prices for UFPI.\n",
      "Fetching data for NVCR...\n",
      "Fetched 251 daily close prices for NVCR.\n",
      "Fetching data for SMCI...\n",
      "Fetched 251 daily close prices for SMCI.\n",
      "Fetching data for PTCT...\n",
      "Fetched 251 daily close prices for PTCT.\n",
      "Fetching data for NBIS...\n",
      "Fetched 30 daily close prices for NBIS.\n",
      "Fetching data for AA...\n",
      "Fetched 251 daily close prices for AA.\n",
      "Fetching data for CENX...\n",
      "Fetched 251 daily close prices for CENX.\n",
      "Fetching data for CSTM...\n",
      "Fetched 251 daily close prices for CSTM.\n",
      "Fetching data for KALU...\n",
      "Fetched 251 daily close prices for KALU.\n",
      "Fetching data for CENX...\n",
      "Fetched 251 daily close prices for CENX.\n",
      "Fetching data for AA...\n",
      "Fetched 251 daily close prices for AA.\n",
      "Fetching data for KALU...\n",
      "Fetched 251 daily close prices for KALU.\n",
      "Fetching data for CSTM...\n",
      "Fetched 251 daily close prices for CSTM.\n",
      "Fetching data for CENX...\n",
      "Fetched 251 daily close prices for CENX.\n",
      "Fetching data for KALU...\n",
      "Fetched 251 daily close prices for KALU.\n",
      "Fetching data for HL...\n",
      "Fetched 251 daily close prices for HL.\n",
      "Fetching data for GATO...\n",
      "Fetched 251 daily close prices for GATO.\n",
      "Fetching data for MUX...\n",
      "Fetched 251 daily close prices for MUX.\n",
      "Fetching data for ACRG...\n",
      "Fetched 251 daily close prices for ACRG.\n",
      "Fetching data for GATO...\n",
      "Fetched 251 daily close prices for GATO.\n",
      "Fetching data for MUX...\n",
      "Fetched 251 daily close prices for MUX.\n",
      "Fetching data for HL...\n",
      "Fetched 251 daily close prices for HL.\n",
      "Fetching data for ACRG...\n",
      "Fetched 251 daily close prices for ACRG.\n",
      "Fetching data for GATO...\n",
      "Fetched 251 daily close prices for GATO.\n",
      "Fetching data for MUX...\n",
      "Fetched 251 daily close prices for MUX.\n",
      "Fetching data for HCC...\n",
      "Fetched 251 daily close prices for HCC.\n",
      "Fetching data for AMR...\n",
      "Fetched 251 daily close prices for AMR.\n",
      "Fetching data for ARCH...\n",
      "Fetched 251 daily close prices for ARCH.\n",
      "Fetching data for SXC...\n",
      "Fetched 251 daily close prices for SXC.\n",
      "Fetching data for METC...\n",
      "Fetched 251 daily close prices for METC.\n",
      "Fetching data for SXC...\n",
      "Fetched 251 daily close prices for SXC.\n",
      "Fetching data for HCC...\n",
      "Fetched 251 daily close prices for HCC.\n",
      "Fetching data for ARCH...\n",
      "Fetched 251 daily close prices for ARCH.\n",
      "Fetching data for AMR...\n",
      "Fetched 251 daily close prices for AMR.\n",
      "Fetching data for METC...\n",
      "Fetched 251 daily close prices for METC.\n",
      "Fetching data for SLVM...\n",
      "Fetched 251 daily close prices for SLVM.\n",
      "Fetching data for MAGN...\n",
      "Fetched 251 daily close prices for MAGN.\n",
      "Fetching data for CLW...\n",
      "Fetched 251 daily close prices for CLW.\n",
      "Fetching data for MERC...\n",
      "Fetched 251 daily close prices for MERC.\n",
      "Fetching data for GLT...\n",
      "Fetched 251 daily close prices for GLT.\n",
      "Fetching data for SLVM...\n",
      "Fetched 251 daily close prices for SLVM.\n",
      "Fetching data for GLT...\n",
      "Fetched 251 daily close prices for GLT.\n",
      "Fetching data for MAGN...\n",
      "Fetched 251 daily close prices for MAGN.\n",
      "Fetching data for CLW...\n",
      "Fetched 251 daily close prices for CLW.\n",
      "Fetching data for MERC...\n",
      "Fetched 251 daily close prices for MERC.\n",
      "Fetching data for RSMXF...\n",
      "Fetched 251 daily close prices for RSMXF.\n",
      "Fetching data for AYASF...\n",
      "Fetched 251 daily close prices for AYASF.\n",
      "Fetching data for SVRSF...\n",
      "Fetched 251 daily close prices for SVRSF.\n",
      "Fetching data for APGOF...\n",
      "Fetched 251 daily close prices for APGOF.\n",
      "Fetching data for KOOYF...\n",
      "Fetched 251 daily close prices for KOOYF.\n",
      "Fetching data for GSVRF...\n",
      "Fetched 251 daily close prices for GSVRF.\n",
      "Fetching data for SLVRF...\n",
      "Fetched 251 daily close prices for SLVRF.\n",
      "Fetching data for RKHNF...\n",
      "Fetched 251 daily close prices for RKHNF.\n",
      "Fetching data for WEDXF...\n",
      "Fetched 251 daily close prices for WEDXF.\n",
      "Fetching data for SVM...\n",
      "Fetched 251 daily close prices for SVM.\n",
      "Stock data saved to stock_data.csv\n",
      "Data fetching and saving complete.\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfdbcf10-c308-4b42-8d2c-ae69cb1e293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script complete. Closing the browser.\n"
     ]
    }
   ],
   "source": [
    "# Close the driver\n",
    "print(\"Script complete. Closing the browser.\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe3e63-8d85-4966-b2a3-cbb98827b722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16c454-9cec-4572-9081-850125942150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
