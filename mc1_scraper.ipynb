{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28828a54-4172-49c2-91d1-0fd9be2ddcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4164e5dd-dff6-4f8c-8126-f0653f94a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome Options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})  # Disable images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcb283a-4923-47ac-b749-3ffd916af63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Chrome anti-bot measures\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b805783-005f-4248-992b-3a79ce3d1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver with Chrome options\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2fbe79-36e6-4b32-ab0a-f5d928ae9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for cookies and initial URLs\n",
    "cookie_file_path = \"cookies.pkl\"\n",
    "base_url = \"https://finance.yahoo.com/\"\n",
    "sectors_url = \"https://finance.yahoo.com/sectors/basic-materials/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cc5208-744f-449d-adb8-2938fd349004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cookies function\n",
    "def save_cookies(driver, path):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(driver.get_cookies(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9ed2e6-2a5d-4713-98d2-27a8f9b076f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cookies function with domain check\n",
    "def load_cookies(driver, path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as file:\n",
    "            cookies = pickle.load(file)\n",
    "            for cookie in cookies:\n",
    "                if \"domain\" in cookie and cookie[\"domain\"] in driver.current_url:\n",
    "                    driver.add_cookie(cookie)\n",
    "            return True\n",
    "    except FileNotFoundError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ff5cc5-cdd2-49cd-a6f2-41c3ef0373e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold industry names\n",
    "industry_names = []\n",
    "\n",
    "def gather_industry_names(driver):\n",
    "    global industry_names\n",
    "    # Reload sectors page if not on it\n",
    "    if driver.current_url != sectors_url:\n",
    "        print(\"Returning to sectors page...\")\n",
    "        driver.get(sectors_url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"tr.yf-k3njn8\"))\n",
    "        )\n",
    "        time.sleep(1)  # Short delay for additional page loading\n",
    "\n",
    "    # Select industry rows after page load\n",
    "    industry_rows = driver.find_elements(By.CSS_SELECTOR, \"tr.yf-k3njn8\")\n",
    "    print(f\"Found {len(industry_rows)} industries.\")\n",
    "\n",
    "    # Extract and clean names of the first 10 industries\n",
    "    industry_names = [\n",
    "        row.find_element(By.CSS_SELECTOR, \"td.name\").text for row in industry_rows[2:len(industry_rows)]#2:\n",
    "    ]\n",
    "    print(\"Collected industry names:\", industry_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16923010-55a1-48d9-8ea0-576c58cd50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls():\n",
    "    # Generate URLs using industry names, replacing spaces with dashes and removing '&'\n",
    "    updated_urls = [\n",
    "        sectors_url + name.lower().replace('&', '').replace(' ', '-').replace('--', '-') + '/' \n",
    "        for name in industry_names\n",
    "    ]\n",
    "    return updated_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a58d82-0d7f-4ac4-b6c7-4b3b6c3622f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract \"/quote/.../\" hrefs from each URL in the list\n",
    "def extract_quote_links(driver, urls):\n",
    "    quote_links = []  # List to hold fully qualified extracted links\n",
    "\n",
    "    for index, url in enumerate(urls):\n",
    "        print(f\"Accessing URL {index + 1}/{len(urls)}: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Delay to allow page load; adjust as needed for speed optimization\n",
    "\n",
    "        # Parse the page source with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Find all hrefs that match \"/quote/.../\"\n",
    "        matched_links = []\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            if re.match(r\"^/quote/.+/$\", href):\n",
    "                full_url = urljoin(base_url, href)  # Prepend base URL\n",
    "                matched_links.append(full_url)\n",
    "\n",
    "            # Stop after collecting the first 10 unique links\n",
    "            if len(matched_links) >= 10:\n",
    "                break\n",
    "\n",
    "        quote_links.extend(matched_links)\n",
    "\n",
    "        print(f\"Extracted {len(matched_links)} links from {url}\")\n",
    "\n",
    "    return quote_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38a838b-e93c-41b7-a526-df025b536b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save extracted links to CSV\n",
    "def save_links_to_csv(links, filename=\"extracted_links.csv\"):\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Link\"])  # Write header\n",
    "        for link in links:\n",
    "            writer.writerow([link])\n",
    "    print(f\"Links saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb770df-9413-44b5-ab54-de6956d61b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry function for operations\n",
    "def retry_operation(func, retries=3, delay=5, *args, **kwargs):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            time.sleep(delay)\n",
    "    print(\"Operation failed after retries.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8c635e1-838f-4db8-92ab-ad5cc324b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch stock data for a single ticker\n",
    "def fetch_stock_data(ticker, period1, period2, interval=\"1d\", cookies=None, headers=None):\n",
    "    base_url = \"https://query1.finance.yahoo.com/v8/finance/chart/\"\n",
    "    query_url = (\n",
    "        f\"{base_url}{ticker}?period1={period1}&period2={period2}\"\n",
    "        f\"&interval={interval}&includePrePost=true&events=div%7Csplit%7Cearn&lang=en-US&region=US\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(query_url, cookies=cookies, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract timestamps and close prices\n",
    "        timestamps = data['chart']['result'][0]['timestamp']\n",
    "        close_prices = data['chart']['result'][0]['indicators']['quote'][0]['close']\n",
    "        \n",
    "        # Convert timestamps to datetime\n",
    "        timestamps = pd.to_datetime(timestamps, unit='s')\n",
    "\n",
    "        # Filter for the last 100 days\n",
    "        timestamps = timestamps[-100:]\n",
    "        close_prices = close_prices[-100:]\n",
    "        \n",
    "        return timestamps, close_prices\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e5a3488-7d9e-477a-bdb5-cc8ade75dc4a",
   "metadata": {},
   "source": [
    "# Function to fetch data for all tickers\n",
    "def fetch_all_tickers_data(links, period1, period2, interval=\"1d\", cookies=None, headers=None):\n",
    "    # Generate a fixed index for the last 100 days with time set to 15:45\n",
    "    target_timestamps = pd.date_range(\n",
    "        end=pd.to_datetime(period2, unit=\"s\"),\n",
    "        periods=100,\n",
    "        freq=\"D\"\n",
    "    ).normalize() + pd.Timedelta(hours=15, minutes=49)  # Set time to 15:49\n",
    "    \n",
    "    # Temporary dictionary to store data\n",
    "    ticker_data = {\"timestamp\": target_timestamps}\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            # Extract the ticker symbol\n",
    "            ticker = link.split('/')[-2]\n",
    "            print(f\"Fetching data for {ticker}...\")\n",
    "            \n",
    "            # Fetch data for the ticker\n",
    "            timestamps, close_prices = fetch_stock_data(\n",
    "                ticker, period1, period2, interval, cookies, headers\n",
    "            )\n",
    "            \n",
    "            if timestamps is not None and close_prices is not None:\n",
    "                # Create a Series for the close prices with timestamps as the index\n",
    "                series = pd.Series(data=close_prices, index=timestamps)\n",
    "                \n",
    "                # Reindex to align with the target timestamps\n",
    "                reindexed_series = series.reindex(target_timestamps, fill_value=np.nan)\n",
    "                \n",
    "                # Store the reindexed data\n",
    "                ticker_data[ticker] = reindexed_series.values\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {link}: {e}\")\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    aggregated_data = pd.DataFrame(ticker_data)\n",
    "    return aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67b13b9-5255-4e62-884c-0e0e30a383e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data for all tickers\n",
    "def fetch_all_tickers_data(links, period1, period2, interval=\"1d\", cookies=None, headers=None):\n",
    "    # Generate a fixed index for the last 100 days with time set to 15:45\n",
    "    target_timestamps = pd.date_range(\n",
    "        end=pd.to_datetime(period2, unit=\"s\"),\n",
    "        periods=100,\n",
    "        freq=\"D\"\n",
    "    ).normalize() + pd.Timedelta(hours=15, minutes=49)  # Set time to 15:49\n",
    "    \n",
    "    # Temporary dictionary to store data\n",
    "    ticker_data = {\"timestamp\": target_timestamps}\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            # Extract the ticker symbol\n",
    "            ticker = link.split('/')[-2]\n",
    "            print(f\"Fetching data for {ticker}...\")\n",
    "            \n",
    "            # Fetch data for the ticker\n",
    "            timestamps, close_prices = fetch_stock_data(\n",
    "                ticker, period1, period2, interval, cookies, headers\n",
    "            )\n",
    "            \n",
    "            if timestamps is not None and close_prices is not None:\n",
    "                # Create a Series for the close prices with timestamps as the index\n",
    "                series = pd.Series(data=close_prices, index=timestamps)\n",
    "                \n",
    "                # Reindex to align with the target timestamps\n",
    "                reindexed_series = series.reindex(target_timestamps, fill_value=np.nan)\n",
    "                \n",
    "                # Store the reindexed data\n",
    "                ticker_data[ticker] = reindexed_series.values\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {link}: {e}\")\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    aggregated_data = pd.DataFrame(ticker_data)\n",
    "    return aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74adc635-89d5-4ba9-a6a9-c6f95758cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aggregated data to CSV\n",
    "def save_data_to_csv(data, filename=\"stock_data.csv\"):\n",
    "    data.to_csv(filename, index=False)\n",
    "    print(f\"Stock data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e809523-2122-4fad-99ef-753222498880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_tickers_data(links, period1, period2, interval=\"1d\", cookies=None, headers=None):\n",
    "    # Generate a fixed index for the last 100 days at 13:30\n",
    "    target_timestamps = pd.date_range(\n",
    "        end=datetime.now().replace(hour=13, minute=30, second=0),\n",
    "        periods=100,\n",
    "        freq=\"D\"\n",
    "    )\n",
    "    \n",
    "    # Temporary dictionary to store data\n",
    "    ticker_data = {\"timestamp\": target_timestamps}\n",
    "\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            # Extract the ticker symbol\n",
    "            ticker = link.split('/')[-2]\n",
    "            print(f\"Fetching data for {ticker}...\")\n",
    "            \n",
    "            # Fetch data for the ticker\n",
    "            timestamps, close_prices = fetch_stock_data(\n",
    "                ticker, period1, period2, interval, cookies, headers\n",
    "            )\n",
    "            \n",
    "            if timestamps is not None and close_prices is not None:\n",
    "                print(f\"Fetched {len(close_prices)} close prices for {ticker}.\")\n",
    "                # Create a Series for the close prices with timestamps as the index\n",
    "                series = pd.Series(data=close_prices, index=timestamps)\n",
    "                \n",
    "                # Reindex to align with the target timestamps\n",
    "                reindexed_series = series.reindex(target_timestamps, fill_value=np.nan)\n",
    "                \n",
    "                # Store the reindexed data\n",
    "                ticker_data[ticker] = reindexed_series.values\n",
    "            else:\n",
    "                print(f\"Warning: No data available for {ticker}.\")\n",
    "                ticker_data[ticker] = [np.nan] * len(target_timestamps)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {link}: {e}\")\n",
    "            ticker_data[ticker] = [np.nan] * len(target_timestamps)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    aggregated_data = pd.DataFrame(ticker_data)\n",
    "    return aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93e90a6e-c735-4154-95fd-24ddeba7da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to handle navigation\n",
    "def main():\n",
    "    print(\"Navigating to Yahoo Finance homepage...\")\n",
    "    driver.get(base_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Handle cookies if they exist\n",
    "    if load_cookies(driver, cookie_file_path):\n",
    "        print(\"Cookies loaded successfully.\")\n",
    "        driver.refresh()\n",
    "    else:\n",
    "        print(\"No cookies found. Accepting cookies manually.\")\n",
    "        try:\n",
    "            accept_button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept all')]\"))\n",
    "            )\n",
    "            accept_button.click()\n",
    "            time.sleep(2)\n",
    "            save_cookies(driver, cookie_file_path)\n",
    "            print(\"Cookies accepted and saved.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error handling cookies:\", e)\n",
    "    \n",
    "    # Navigate to Basic Materials sector\n",
    "    print(\"Navigating to Basic Materials sector...\")\n",
    "    driver.get(sectors_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Navigate to each industry and collect company links\n",
    "    #navigate_to_industry()\n",
    "    gather_industry_names(driver)\n",
    "    updated_urls = generate_urls()\n",
    "\n",
    "    print(\"List of updated URLs for the first 10 industries:\")\n",
    "    for url in updated_urls:\n",
    "        print(url)\n",
    "\n",
    "    # Extract quote links from each updated URL\n",
    "    print(\"Extracting /quote/.../ links from each industry page...\")\n",
    "    extracted_links = retry_operation(extract_quote_links, retries=3, driver=driver, urls=updated_urls)\n",
    "    if not extracted_links:\n",
    "        print(\"Failed to extract links. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    print(\"Collected full quote links:\") if extracted_links else print(\"Links could not be collected\")\n",
    "\n",
    "    # Save the extracted links\n",
    "    save_links_to_csv(extracted_links)\n",
    "    print(\"Extraction and saving complete.\")\n",
    "    \n",
    "    for link in extracted_links:\n",
    "        print(link)\n",
    "\n",
    "    # Fetch stock data using Yahoo AJAX endpoint\n",
    "    print(\"Fetching stock data for all links...\")\n",
    "    \n",
    "    # Define a fixed timestamp range\n",
    "    period1 = 1724080800  # Example start timestamp\n",
    "    period2 = 1733104800  # Example end timestamp\n",
    "\n",
    "    # Define headers and cookies\n",
    "    headers = {\n",
    "        \"accept\": \"*/*\",\n",
    "        \"accept-encoding\": \"gzip, deflate, br, zstd\",\n",
    "        \"accept-language\": \"de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n",
    "    }\n",
    "\n",
    "    cookies = {\n",
    "        \"GUC\": \"AQABCAFnJy1nV0IgvASK&s=AQAAAJB-qKHi&g=ZyXotw\",\n",
    "        \"A1\": \"d=AQABBK3oJWcCEL768yJfkpdKJoPN52K9l3QFEgABCAEtJ2dXZ7u9b2UBAiAAAAcIpuglZ8iQvhs&S=AQAAAq11kqwbV-Cl4YdEYNtEpg8\",\n",
    "        \"A3\": \"d=AQABBK3oJWcCEL768yJfkpdKJoPN52K9l3QFEgABCAEtJ2dXZ7u9b2UBAiAAAAcIpuglZ8iQvhs&S=AQAAAq11kqwbV-Cl4YdEYNtEpg8\",\n",
    "        \"A1S\": \"d=AQABBK3oJWcCEL768yJfkpdKJoPN52K9l3QFEgABCAEtJ2dXZ7u9b2UBAiAAAAcIpuglZ8iQvhs&S=AQAAAq11kqwbV-Cl4YdEYNtEpg8\",\n",
    "        \"cmp\": \"t=1733097066&j=1&u=1---&v=54\",\n",
    "        \"EuConsent\": \"CQHdjMAQHdjMAAOACKENBRFgAAAAAAAAACiQAAAAAAAA\",\n",
    "        \"PRF\": \"t=LIN%252BGC%253DF\",\n",
    "    }\n",
    "\n",
    "    # Fetch and save stock data\n",
    "    stock_data = fetch_all_tickers_data(extracted_links, period1, period2, interval=\"1d\", cookies=cookies, headers=headers)\n",
    "    save_data_to_csv(stock_data)\n",
    "    print(\"Data fetching and saving complete.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "572ea6d3-bea3-4d01-b936-408119e5b6cf",
   "metadata": {},
   "source": [
    "# Original Main function to handle navigation\n",
    "def main():\n",
    "    print(\"Navigating to Yahoo Finance homepage...\")\n",
    "    driver.get(base_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Handle cookies if they exist\n",
    "    if load_cookies(driver, cookie_file_path):\n",
    "        print(\"Cookies loaded successfully.\")\n",
    "        driver.refresh()\n",
    "    else:\n",
    "        print(\"No cookies found. Accepting cookies manually.\")\n",
    "        try:\n",
    "            accept_button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept all')]\"))\n",
    "            )\n",
    "            accept_button.click()\n",
    "            time.sleep(2)\n",
    "            save_cookies(driver, cookie_file_path)\n",
    "            print(\"Cookies accepted and saved.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error handling cookies:\", e)\n",
    "    \n",
    "    # Navigate to Basic Materials sector\n",
    "    print(\"Navigating to Basic Materials sector...\")\n",
    "    driver.get(sectors_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Navigate to each industry and collect company links\n",
    "    #navigate_to_industry()\n",
    "    gather_industry_names(driver)\n",
    "    updated_urls = generate_urls()\n",
    "\n",
    "    print(\"List of updated URLs for the first 10 industries:\")\n",
    "    for url in updated_urls:\n",
    "        print(url)\n",
    "\n",
    "    # Extract quote links from each updated URL\n",
    "    print(\"Extracting /quote/.../ links from each industry page...\")\n",
    "    extracted_links = extract_quote_links(driver, updated_urls)\n",
    "    \n",
    "    print(\"Collected full quote links:\") if extracted_links else print(\"Links could not be collected\")\n",
    "    for link in extracted_links:\n",
    "        print(link)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "976582b1-9554-40bb-a2fc-fbd8ad44d8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to Yahoo Finance homepage...\n",
      "Cookies loaded successfully.\n",
      "Navigating to Basic Materials sector...\n",
      "Found 16 industries.\n",
      "Collected industry names: ['Specialty Chemicals', 'Gold', 'Building Materials', 'Copper', 'Steel', 'Agricultural Inputs', 'Chemicals', 'Other Industrial Metals & Mining', 'Lumber & Wood Production', 'Aluminum', 'Other Precious Metals & Mining', 'Coking Coal', 'Paper & Paper Products', 'Silver']\n",
      "List of updated URLs for the first 10 industries:\n",
      "https://finance.yahoo.com/sectors/basic-materials/specialty-chemicals/\n",
      "https://finance.yahoo.com/sectors/basic-materials/gold/\n",
      "https://finance.yahoo.com/sectors/basic-materials/building-materials/\n",
      "https://finance.yahoo.com/sectors/basic-materials/copper/\n",
      "https://finance.yahoo.com/sectors/basic-materials/steel/\n",
      "https://finance.yahoo.com/sectors/basic-materials/agricultural-inputs/\n",
      "https://finance.yahoo.com/sectors/basic-materials/chemicals/\n",
      "https://finance.yahoo.com/sectors/basic-materials/other-industrial-metals-mining/\n",
      "https://finance.yahoo.com/sectors/basic-materials/lumber-wood-production/\n",
      "https://finance.yahoo.com/sectors/basic-materials/aluminum/\n",
      "https://finance.yahoo.com/sectors/basic-materials/other-precious-metals-mining/\n",
      "https://finance.yahoo.com/sectors/basic-materials/coking-coal/\n",
      "https://finance.yahoo.com/sectors/basic-materials/paper-paper-products/\n",
      "https://finance.yahoo.com/sectors/basic-materials/silver/\n",
      "Extracting /quote/.../ links from each industry page...\n",
      "Accessing URL 1/14: https://finance.yahoo.com/sectors/basic-materials/specialty-chemicals/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/specialty-chemicals/\n",
      "Accessing URL 2/14: https://finance.yahoo.com/sectors/basic-materials/gold/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/gold/\n",
      "Accessing URL 3/14: https://finance.yahoo.com/sectors/basic-materials/building-materials/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/building-materials/\n",
      "Accessing URL 4/14: https://finance.yahoo.com/sectors/basic-materials/copper/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/copper/\n",
      "Accessing URL 5/14: https://finance.yahoo.com/sectors/basic-materials/steel/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/steel/\n",
      "Accessing URL 6/14: https://finance.yahoo.com/sectors/basic-materials/agricultural-inputs/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/agricultural-inputs/\n",
      "Accessing URL 7/14: https://finance.yahoo.com/sectors/basic-materials/chemicals/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/chemicals/\n",
      "Accessing URL 8/14: https://finance.yahoo.com/sectors/basic-materials/other-industrial-metals-mining/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/other-industrial-metals-mining/\n",
      "Accessing URL 9/14: https://finance.yahoo.com/sectors/basic-materials/lumber-wood-production/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/lumber-wood-production/\n",
      "Accessing URL 10/14: https://finance.yahoo.com/sectors/basic-materials/aluminum/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/aluminum/\n",
      "Accessing URL 11/14: https://finance.yahoo.com/sectors/basic-materials/other-precious-metals-mining/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/other-precious-metals-mining/\n",
      "Accessing URL 12/14: https://finance.yahoo.com/sectors/basic-materials/coking-coal/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/coking-coal/\n",
      "Accessing URL 13/14: https://finance.yahoo.com/sectors/basic-materials/paper-paper-products/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/paper-paper-products/\n",
      "Accessing URL 14/14: https://finance.yahoo.com/sectors/basic-materials/silver/\n",
      "Extracted 10 links from https://finance.yahoo.com/sectors/basic-materials/silver/\n",
      "Collected full quote links:\n",
      "Links saved to extracted_links.csv\n",
      "Extraction and saving complete.\n",
      "https://finance.yahoo.com/quote/LIN/\n",
      "https://finance.yahoo.com/quote/SHW/\n",
      "https://finance.yahoo.com/quote/APD/\n",
      "https://finance.yahoo.com/quote/ECL/\n",
      "https://finance.yahoo.com/quote/DD/\n",
      "https://finance.yahoo.com/quote/PPG/\n",
      "https://finance.yahoo.com/quote/LYB/\n",
      "https://finance.yahoo.com/quote/IFF/\n",
      "https://finance.yahoo.com/quote/RPM/\n",
      "https://finance.yahoo.com/quote/WLK/\n",
      "https://finance.yahoo.com/quote/NEM/\n",
      "https://finance.yahoo.com/quote/AU/\n",
      "https://finance.yahoo.com/quote/RGLD/\n",
      "https://finance.yahoo.com/quote/CDE/\n",
      "https://finance.yahoo.com/quote/SA/\n",
      "https://finance.yahoo.com/quote/CTGO/\n",
      "https://finance.yahoo.com/quote/CMCL/\n",
      "https://finance.yahoo.com/quote/IDR/\n",
      "https://finance.yahoo.com/quote/FTCO/\n",
      "https://finance.yahoo.com/quote/USAU/\n",
      "https://finance.yahoo.com/quote/CRH/\n",
      "https://finance.yahoo.com/quote/VMC/\n",
      "https://finance.yahoo.com/quote/MLM/\n",
      "https://finance.yahoo.com/quote/EXP/\n",
      "https://finance.yahoo.com/quote/SUM/\n",
      "https://finance.yahoo.com/quote/KNF/\n",
      "https://finance.yahoo.com/quote/BCC/\n",
      "https://finance.yahoo.com/quote/USLM/\n",
      "https://finance.yahoo.com/quote/TGLS/\n",
      "https://finance.yahoo.com/quote/SMID/\n",
      "https://finance.yahoo.com/quote/SCCO/\n",
      "https://finance.yahoo.com/quote/FCX/\n",
      "https://finance.yahoo.com/quote/IE/\n",
      "https://finance.yahoo.com/quote/MTAL/\n",
      "https://finance.yahoo.com/quote/SCCO/\n",
      "https://finance.yahoo.com/quote/FCX/\n",
      "https://finance.yahoo.com/quote/MTAL/\n",
      "https://finance.yahoo.com/quote/IE/\n",
      "https://finance.yahoo.com/quote/SCCO/\n",
      "https://finance.yahoo.com/quote/FCX/\n",
      "https://finance.yahoo.com/quote/NUE/\n",
      "https://finance.yahoo.com/quote/STLD/\n",
      "https://finance.yahoo.com/quote/RS/\n",
      "https://finance.yahoo.com/quote/X/\n",
      "https://finance.yahoo.com/quote/CMC/\n",
      "https://finance.yahoo.com/quote/CLF/\n",
      "https://finance.yahoo.com/quote/WS/\n",
      "https://finance.yahoo.com/quote/MTUS/\n",
      "https://finance.yahoo.com/quote/RDUS/\n",
      "https://finance.yahoo.com/quote/ZEUS/\n",
      "https://finance.yahoo.com/quote/CTVA/\n",
      "https://finance.yahoo.com/quote/CF/\n",
      "https://finance.yahoo.com/quote/MOS/\n",
      "https://finance.yahoo.com/quote/FMC/\n",
      "https://finance.yahoo.com/quote/SMG/\n",
      "https://finance.yahoo.com/quote/UAN/\n",
      "https://finance.yahoo.com/quote/LVRO/\n",
      "https://finance.yahoo.com/quote/BIOX/\n",
      "https://finance.yahoo.com/quote/IPI/\n",
      "https://finance.yahoo.com/quote/AVD/\n",
      "https://finance.yahoo.com/quote/DOW/\n",
      "https://finance.yahoo.com/quote/CE/\n",
      "https://finance.yahoo.com/quote/OLN/\n",
      "https://finance.yahoo.com/quote/HUN/\n",
      "https://finance.yahoo.com/quote/TROX/\n",
      "https://finance.yahoo.com/quote/ASIX/\n",
      "https://finance.yahoo.com/quote/WLKP/\n",
      "https://finance.yahoo.com/quote/REX/\n",
      "https://finance.yahoo.com/quote/VHI/\n",
      "https://finance.yahoo.com/quote/GPRE/\n",
      "https://finance.yahoo.com/quote/MP/\n",
      "https://finance.yahoo.com/quote/MTRN/\n",
      "https://finance.yahoo.com/quote/NEXA/\n",
      "https://finance.yahoo.com/quote/CMP/\n",
      "https://finance.yahoo.com/quote/CRML/\n",
      "https://finance.yahoo.com/quote/LZM/\n",
      "https://finance.yahoo.com/quote/GRO/\n",
      "https://finance.yahoo.com/quote/PLL/\n",
      "https://finance.yahoo.com/quote/USGO/\n",
      "https://finance.yahoo.com/quote/ATLX/\n",
      "https://finance.yahoo.com/quote/UFPI/\n",
      "https://finance.yahoo.com/quote/SSD/\n",
      "https://finance.yahoo.com/quote/UFPI/\n",
      "https://finance.yahoo.com/quote/SSD/\n",
      "https://finance.yahoo.com/quote/SSD/\n",
      "https://finance.yahoo.com/quote/UFPI/\n",
      "https://finance.yahoo.com/quote/LTHM.L/\n",
      "https://finance.yahoo.com/quote/LTHP.L/\n",
      "https://finance.yahoo.com/quote/NWGL/\n",
      "https://finance.yahoo.com/quote/ICLTF/\n",
      "https://finance.yahoo.com/quote/AA/\n",
      "https://finance.yahoo.com/quote/CENX/\n",
      "https://finance.yahoo.com/quote/CSTM/\n",
      "https://finance.yahoo.com/quote/KALU/\n",
      "https://finance.yahoo.com/quote/CENX/\n",
      "https://finance.yahoo.com/quote/AA/\n",
      "https://finance.yahoo.com/quote/KALU/\n",
      "https://finance.yahoo.com/quote/CSTM/\n",
      "https://finance.yahoo.com/quote/CENX/\n",
      "https://finance.yahoo.com/quote/KALU/\n",
      "https://finance.yahoo.com/quote/HL/\n",
      "https://finance.yahoo.com/quote/GATO/\n",
      "https://finance.yahoo.com/quote/MUX/\n",
      "https://finance.yahoo.com/quote/ACRG/\n",
      "https://finance.yahoo.com/quote/GATO/\n",
      "https://finance.yahoo.com/quote/MUX/\n",
      "https://finance.yahoo.com/quote/HL/\n",
      "https://finance.yahoo.com/quote/ACRG/\n",
      "https://finance.yahoo.com/quote/GATO/\n",
      "https://finance.yahoo.com/quote/MUX/\n",
      "https://finance.yahoo.com/quote/HCC/\n",
      "https://finance.yahoo.com/quote/AMR/\n",
      "https://finance.yahoo.com/quote/ARCH/\n",
      "https://finance.yahoo.com/quote/SXC/\n",
      "https://finance.yahoo.com/quote/METC/\n",
      "https://finance.yahoo.com/quote/SXC/\n",
      "https://finance.yahoo.com/quote/HCC/\n",
      "https://finance.yahoo.com/quote/ARCH/\n",
      "https://finance.yahoo.com/quote/METC/\n",
      "https://finance.yahoo.com/quote/AMR/\n",
      "https://finance.yahoo.com/quote/SLVM/\n",
      "https://finance.yahoo.com/quote/MAGN/\n",
      "https://finance.yahoo.com/quote/CLW/\n",
      "https://finance.yahoo.com/quote/MERC/\n",
      "https://finance.yahoo.com/quote/GLT/\n",
      "https://finance.yahoo.com/quote/SLVM/\n",
      "https://finance.yahoo.com/quote/GLT/\n",
      "https://finance.yahoo.com/quote/MAGN/\n",
      "https://finance.yahoo.com/quote/CLW/\n",
      "https://finance.yahoo.com/quote/MERC/\n",
      "https://finance.yahoo.com/quote/KOOYF/\n",
      "https://finance.yahoo.com/quote/GSVRF/\n",
      "https://finance.yahoo.com/quote/SLVRF/\n",
      "https://finance.yahoo.com/quote/RKHNF/\n",
      "https://finance.yahoo.com/quote/WEDXF/\n",
      "https://finance.yahoo.com/quote/SVM/\n",
      "https://finance.yahoo.com/quote/DOMO/\n",
      "https://finance.yahoo.com/quote/%5EGSPC/\n",
      "https://finance.yahoo.com/quote/RSMXF/\n",
      "https://finance.yahoo.com/quote/SVRSF/\n",
      "Fetching stock data for all links...\n",
      "Fetching data for LIN...\n",
      "Fetched 73 close prices for LIN.\n",
      "Fetching data for SHW...\n",
      "Fetched 73 close prices for SHW.\n",
      "Fetching data for APD...\n",
      "Fetched 73 close prices for APD.\n",
      "Fetching data for ECL...\n",
      "Fetched 73 close prices for ECL.\n",
      "Fetching data for DD...\n",
      "Fetched 73 close prices for DD.\n",
      "Fetching data for PPG...\n",
      "Fetched 73 close prices for PPG.\n",
      "Fetching data for LYB...\n",
      "Fetched 73 close prices for LYB.\n",
      "Fetching data for IFF...\n",
      "Fetched 73 close prices for IFF.\n",
      "Fetching data for RPM...\n",
      "Fetched 73 close prices for RPM.\n",
      "Fetching data for WLK...\n",
      "Fetched 73 close prices for WLK.\n",
      "Fetching data for NEM...\n",
      "Fetched 73 close prices for NEM.\n",
      "Fetching data for AU...\n",
      "Fetched 73 close prices for AU.\n",
      "Fetching data for RGLD...\n",
      "Fetched 73 close prices for RGLD.\n",
      "Fetching data for CDE...\n",
      "Fetched 73 close prices for CDE.\n",
      "Fetching data for SA...\n",
      "Fetched 73 close prices for SA.\n",
      "Fetching data for CTGO...\n",
      "Fetched 73 close prices for CTGO.\n",
      "Fetching data for CMCL...\n",
      "Fetched 73 close prices for CMCL.\n",
      "Fetching data for IDR...\n",
      "Fetched 73 close prices for IDR.\n",
      "Fetching data for FTCO...\n",
      "Fetched 73 close prices for FTCO.\n",
      "Fetching data for USAU...\n",
      "Fetched 73 close prices for USAU.\n",
      "Fetching data for CRH...\n",
      "Fetched 73 close prices for CRH.\n",
      "Fetching data for VMC...\n",
      "Fetched 73 close prices for VMC.\n",
      "Fetching data for MLM...\n",
      "Fetched 73 close prices for MLM.\n",
      "Fetching data for EXP...\n",
      "Fetched 73 close prices for EXP.\n",
      "Fetching data for SUM...\n",
      "Fetched 73 close prices for SUM.\n",
      "Fetching data for KNF...\n",
      "Fetched 73 close prices for KNF.\n",
      "Fetching data for BCC...\n",
      "Fetched 73 close prices for BCC.\n",
      "Fetching data for USLM...\n",
      "Fetched 73 close prices for USLM.\n",
      "Fetching data for TGLS...\n",
      "Fetched 73 close prices for TGLS.\n",
      "Fetching data for SMID...\n",
      "Fetched 73 close prices for SMID.\n",
      "Fetching data for SCCO...\n",
      "Fetched 73 close prices for SCCO.\n",
      "Fetching data for FCX...\n",
      "Fetched 73 close prices for FCX.\n",
      "Fetching data for IE...\n",
      "Fetched 73 close prices for IE.\n",
      "Fetching data for MTAL...\n",
      "Fetched 73 close prices for MTAL.\n",
      "Fetching data for SCCO...\n",
      "Fetched 73 close prices for SCCO.\n",
      "Fetching data for FCX...\n",
      "Fetched 73 close prices for FCX.\n",
      "Fetching data for MTAL...\n",
      "Fetched 73 close prices for MTAL.\n",
      "Fetching data for IE...\n",
      "Fetched 73 close prices for IE.\n",
      "Fetching data for SCCO...\n",
      "Fetched 73 close prices for SCCO.\n",
      "Fetching data for FCX...\n",
      "Fetched 73 close prices for FCX.\n",
      "Fetching data for NUE...\n",
      "Fetched 73 close prices for NUE.\n",
      "Fetching data for STLD...\n",
      "Fetched 73 close prices for STLD.\n",
      "Fetching data for RS...\n",
      "Fetched 73 close prices for RS.\n",
      "Fetching data for X...\n",
      "Fetched 73 close prices for X.\n",
      "Fetching data for CMC...\n",
      "Fetched 73 close prices for CMC.\n",
      "Fetching data for CLF...\n",
      "Fetched 73 close prices for CLF.\n",
      "Fetching data for WS...\n",
      "Fetched 73 close prices for WS.\n",
      "Fetching data for MTUS...\n",
      "Fetched 73 close prices for MTUS.\n",
      "Fetching data for RDUS...\n",
      "Fetched 73 close prices for RDUS.\n",
      "Fetching data for ZEUS...\n",
      "Fetched 73 close prices for ZEUS.\n",
      "Fetching data for CTVA...\n",
      "Fetched 73 close prices for CTVA.\n",
      "Fetching data for CF...\n",
      "Fetched 73 close prices for CF.\n",
      "Fetching data for MOS...\n",
      "Fetched 73 close prices for MOS.\n",
      "Fetching data for FMC...\n",
      "Fetched 73 close prices for FMC.\n",
      "Fetching data for SMG...\n",
      "Fetched 73 close prices for SMG.\n",
      "Fetching data for UAN...\n",
      "Fetched 73 close prices for UAN.\n",
      "Fetching data for LVRO...\n",
      "Fetched 73 close prices for LVRO.\n",
      "Fetching data for BIOX...\n",
      "Fetched 73 close prices for BIOX.\n",
      "Fetching data for IPI...\n",
      "Fetched 73 close prices for IPI.\n",
      "Fetching data for AVD...\n",
      "Fetched 73 close prices for AVD.\n",
      "Fetching data for DOW...\n",
      "Fetched 73 close prices for DOW.\n",
      "Fetching data for CE...\n",
      "Fetched 73 close prices for CE.\n",
      "Fetching data for OLN...\n",
      "Fetched 73 close prices for OLN.\n",
      "Fetching data for HUN...\n",
      "Fetched 73 close prices for HUN.\n",
      "Fetching data for TROX...\n",
      "Fetched 73 close prices for TROX.\n",
      "Fetching data for ASIX...\n",
      "Fetched 73 close prices for ASIX.\n",
      "Fetching data for WLKP...\n",
      "Fetched 73 close prices for WLKP.\n",
      "Fetching data for REX...\n",
      "Fetched 73 close prices for REX.\n",
      "Fetching data for VHI...\n",
      "Fetched 73 close prices for VHI.\n",
      "Fetching data for GPRE...\n",
      "Fetched 73 close prices for GPRE.\n",
      "Fetching data for MP...\n",
      "Fetched 73 close prices for MP.\n",
      "Fetching data for MTRN...\n",
      "Fetched 73 close prices for MTRN.\n",
      "Fetching data for NEXA...\n",
      "Fetched 73 close prices for NEXA.\n",
      "Fetching data for CMP...\n",
      "Fetched 73 close prices for CMP.\n",
      "Fetching data for CRML...\n",
      "Fetched 73 close prices for CRML.\n",
      "Fetching data for LZM...\n",
      "Fetched 73 close prices for LZM.\n",
      "Fetching data for GRO...\n",
      "Fetched 2 close prices for GRO.\n",
      "Fetching data for PLL...\n",
      "Fetched 73 close prices for PLL.\n",
      "Fetching data for USGO...\n",
      "Fetched 73 close prices for USGO.\n",
      "Fetching data for ATLX...\n",
      "Fetched 73 close prices for ATLX.\n",
      "Fetching data for UFPI...\n",
      "Fetched 73 close prices for UFPI.\n",
      "Fetching data for SSD...\n",
      "Fetched 73 close prices for SSD.\n",
      "Fetching data for UFPI...\n",
      "Fetched 73 close prices for UFPI.\n",
      "Fetching data for SSD...\n",
      "Fetched 73 close prices for SSD.\n",
      "Fetching data for SSD...\n",
      "Fetched 73 close prices for SSD.\n",
      "Fetching data for UFPI...\n",
      "Fetched 73 close prices for UFPI.\n",
      "Fetching data for LTHM.L...\n",
      "Fetched 74 close prices for LTHM.L.\n",
      "Fetching data for LTHP.L...\n",
      "Fetched 74 close prices for LTHP.L.\n",
      "Fetching data for NWGL...\n",
      "Fetched 73 close prices for NWGL.\n",
      "Fetching data for ICLTF...\n",
      "Fetched 73 close prices for ICLTF.\n",
      "Fetching data for AA...\n",
      "Fetched 73 close prices for AA.\n",
      "Fetching data for CENX...\n",
      "Fetched 73 close prices for CENX.\n",
      "Fetching data for CSTM...\n",
      "Fetched 73 close prices for CSTM.\n",
      "Fetching data for KALU...\n",
      "Fetched 73 close prices for KALU.\n",
      "Fetching data for CENX...\n",
      "Fetched 73 close prices for CENX.\n",
      "Fetching data for AA...\n",
      "Fetched 73 close prices for AA.\n",
      "Fetching data for KALU...\n",
      "Fetched 73 close prices for KALU.\n",
      "Fetching data for CSTM...\n",
      "Fetched 73 close prices for CSTM.\n",
      "Fetching data for CENX...\n",
      "Fetched 73 close prices for CENX.\n",
      "Fetching data for KALU...\n",
      "Fetched 73 close prices for KALU.\n",
      "Fetching data for HL...\n",
      "Fetched 73 close prices for HL.\n",
      "Fetching data for GATO...\n",
      "Fetched 73 close prices for GATO.\n",
      "Fetching data for MUX...\n",
      "Fetched 73 close prices for MUX.\n",
      "Fetching data for ACRG...\n",
      "Fetched 73 close prices for ACRG.\n",
      "Fetching data for GATO...\n",
      "Fetched 73 close prices for GATO.\n",
      "Fetching data for MUX...\n",
      "Fetched 73 close prices for MUX.\n",
      "Fetching data for HL...\n",
      "Fetched 73 close prices for HL.\n",
      "Fetching data for ACRG...\n",
      "Fetched 73 close prices for ACRG.\n",
      "Fetching data for GATO...\n",
      "Fetched 73 close prices for GATO.\n",
      "Fetching data for MUX...\n",
      "Fetched 73 close prices for MUX.\n",
      "Fetching data for HCC...\n",
      "Fetched 73 close prices for HCC.\n",
      "Fetching data for AMR...\n",
      "Fetched 73 close prices for AMR.\n",
      "Fetching data for ARCH...\n",
      "Fetched 73 close prices for ARCH.\n",
      "Fetching data for SXC...\n",
      "Fetched 73 close prices for SXC.\n",
      "Fetching data for METC...\n",
      "Fetched 73 close prices for METC.\n",
      "Fetching data for SXC...\n",
      "Fetched 73 close prices for SXC.\n",
      "Fetching data for HCC...\n",
      "Fetched 73 close prices for HCC.\n",
      "Fetching data for ARCH...\n",
      "Fetched 73 close prices for ARCH.\n",
      "Fetching data for METC...\n",
      "Fetched 73 close prices for METC.\n",
      "Fetching data for AMR...\n",
      "Fetched 73 close prices for AMR.\n",
      "Fetching data for SLVM...\n",
      "Fetched 73 close prices for SLVM.\n",
      "Fetching data for MAGN...\n",
      "Fetched 73 close prices for MAGN.\n",
      "Fetching data for CLW...\n",
      "Fetched 73 close prices for CLW.\n",
      "Fetching data for MERC...\n",
      "Fetched 73 close prices for MERC.\n",
      "Fetching data for GLT...\n",
      "Fetched 73 close prices for GLT.\n",
      "Fetching data for SLVM...\n",
      "Fetched 73 close prices for SLVM.\n",
      "Fetching data for GLT...\n",
      "Fetched 73 close prices for GLT.\n",
      "Fetching data for MAGN...\n",
      "Fetched 73 close prices for MAGN.\n",
      "Fetching data for CLW...\n",
      "Fetched 73 close prices for CLW.\n",
      "Fetching data for MERC...\n",
      "Fetched 73 close prices for MERC.\n",
      "Fetching data for KOOYF...\n",
      "Fetched 73 close prices for KOOYF.\n",
      "Fetching data for GSVRF...\n",
      "Fetched 73 close prices for GSVRF.\n",
      "Fetching data for SLVRF...\n",
      "Fetched 73 close prices for SLVRF.\n",
      "Fetching data for RKHNF...\n",
      "Fetched 73 close prices for RKHNF.\n",
      "Fetching data for WEDXF...\n",
      "Fetched 73 close prices for WEDXF.\n",
      "Fetching data for SVM...\n",
      "Fetched 73 close prices for SVM.\n",
      "Fetching data for DOMO...\n",
      "Fetched 73 close prices for DOMO.\n",
      "Fetching data for %5EGSPC...\n",
      "Fetched 73 close prices for %5EGSPC.\n",
      "Fetching data for RSMXF...\n",
      "Fetched 73 close prices for RSMXF.\n",
      "Fetching data for SVRSF...\n",
      "Fetched 73 close prices for SVRSF.\n",
      "Stock data saved to stock_data.csv\n",
      "Data fetching and saving complete.\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfdbcf10-c308-4b42-8d2c-ae69cb1e293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script complete. Closing the browser.\n"
     ]
    }
   ],
   "source": [
    "# Close the driver\n",
    "print(\"Script complete. Closing the browser.\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe3e63-8d85-4966-b2a3-cbb98827b722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16c454-9cec-4572-9081-850125942150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
